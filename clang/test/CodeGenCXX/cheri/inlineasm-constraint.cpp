// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature
// RUN: %cheri_cc1 -emit-llvm -O1 %s -o -  | FileCheck %s -check-prefix HYBRID
// RUN: %cheri_purecap_cc1 -emit-llvm -O1 %s -o -  | %cheri_FileCheck %s -check-prefix PURECAP

template <class Tp>
__attribute__((always_inline)) void DoNotOptimize(Tp& value) {
#ifdef __CHERI_PURE_CAPABILITY__
  asm volatile("clb $zero, $zero, %0" : "+r,m"(value) : : "memory");
#else
  asm volatile("lb $zero, %0" : "+r,m"(value) : : "memory");
#endif
// asm volatile("" : "+m,r"(value) : : "memory");
}

char DummyData4[4];
char DummyData8[8];
char DummyData16[16];
char DummyData32[32];
char DummyData64[64];

// HYBRID-LABEL: define {{[^@]+}}@_Z4testv
// HYBRID-SAME: () local_unnamed_addr #[[ATTR0:[0-9]+]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = load i32, ptr @DummyData4, align 1
// HYBRID-NEXT:    tail call void asm sideeffect "lb $$zero, $0", "=*r|m,0,~{memory},~{$1}"(ptr nonnull elementtype([4 x i8]) @DummyData4, i32 [[TMP0]]) #[[ATTR1:[0-9]+]], !srcloc !2
// HYBRID-NEXT:    [[TMP1:%.*]] = load i64, ptr @DummyData8, align 1
// HYBRID-NEXT:    tail call void asm sideeffect "lb $$zero, $0", "=*r|m,0,~{memory},~{$1}"(ptr nonnull elementtype([8 x i8]) @DummyData8, i64 [[TMP1]]) #[[ATTR1]], !srcloc !2
// HYBRID-NEXT:    tail call void asm sideeffect "lb $$zero, $0", "=*r|m,*0,~{memory},~{$1}"(ptr nonnull elementtype([16 x i8]) @DummyData16, ptr nonnull elementtype([16 x i8]) @DummyData16) #[[ATTR1]], !srcloc !2
// HYBRID-NEXT:    tail call void asm sideeffect "lb $$zero, $0", "=*r|m,*0,~{memory},~{$1}"(ptr nonnull elementtype([32 x i8]) @DummyData32, ptr nonnull elementtype([32 x i8]) @DummyData32) #[[ATTR1]], !srcloc !2
// HYBRID-NEXT:    tail call void asm sideeffect "lb $$zero, $0", "=*r|m,*0,~{memory},~{$1}"(ptr nonnull elementtype([64 x i8]) @DummyData64, ptr nonnull elementtype([64 x i8]) @DummyData64) #[[ATTR1]], !srcloc !2
// HYBRID-NEXT:    [[TMP2:%.*]] = load i8, ptr @DummyData4, align 1, !tbaa [[TBAA3:![0-9]+]]
// HYBRID-NEXT:    ret i8 [[TMP2]]
//
// PURECAP-LABEL: define {{[^@]+}}@_Z4testv
// PURECAP-SAME: () local_unnamed_addr addrspace(200) #[[ATTR0:[0-9]+]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = load i32, ptr addrspace(200) @DummyData4, align 1
// PURECAP-NEXT:    tail call void asm sideeffect "clb $$zero, $$zero, $0", "=*r|m,0,~{memory},~{$1}"(ptr addrspace(200) nonnull elementtype([4 x i8]) @DummyData4, i32 [[TMP0]]) #[[ATTR1:[0-9]+]], !srcloc !2
// PURECAP-NEXT:    [[TMP1:%.*]] = load i64, ptr addrspace(200) @DummyData8, align 1
// PURECAP-NEXT:    tail call void asm sideeffect "clb $$zero, $$zero, $0", "=*r|m,0,~{memory},~{$1}"(ptr addrspace(200) nonnull elementtype([8 x i8]) @DummyData8, i64 [[TMP1]]) #[[ATTR1]], !srcloc !2
// PURECAP-NEXT:    tail call void asm sideeffect "clb $$zero, $$zero, $0", "=*r|m,*0,~{memory},~{$1}"(ptr addrspace(200) nonnull elementtype([16 x i8]) @DummyData16, ptr addrspace(200) nonnull elementtype([16 x i8]) @DummyData16) #[[ATTR1]], !srcloc !2
// PURECAP-NEXT:    tail call void asm sideeffect "clb $$zero, $$zero, $0", "=*r|m,*0,~{memory},~{$1}"(ptr addrspace(200) nonnull elementtype([32 x i8]) @DummyData32, ptr addrspace(200) nonnull elementtype([32 x i8]) @DummyData32) #[[ATTR1]], !srcloc !2
// PURECAP-NEXT:    tail call void asm sideeffect "clb $$zero, $$zero, $0", "=*r|m,*0,~{memory},~{$1}"(ptr addrspace(200) nonnull elementtype([64 x i8]) @DummyData64, ptr addrspace(200) nonnull elementtype([64 x i8]) @DummyData64) #[[ATTR1]], !srcloc !2
// PURECAP-NEXT:    [[TMP2:%.*]] = load i8, ptr addrspace(200) @DummyData4, align 1, !tbaa [[TBAA3:![0-9]+]]
// PURECAP-NEXT:    ret i8 [[TMP2]]
//
char test() {
  DoNotOptimize(DummyData4);
  DoNotOptimize(DummyData8);
  DoNotOptimize(DummyData16);
  DoNotOptimize(DummyData32);
  DoNotOptimize(DummyData64);
  return DummyData4[0];
}

// HYBRID-LABEL: define {{[^@]+}}@_Z8test_ptrPv
// HYBRID-SAME: (ptr noundef [[P:%.*]]) local_unnamed_addr #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[P_ADDR:%.*]] = alloca ptr, align 8
// HYBRID-NEXT:    store ptr [[P]], ptr [[P_ADDR]], align 8, !tbaa [[TBAA6:![0-9]+]]
// HYBRID-NEXT:    call void asm sideeffect "lb $$zero, $0", "=*r|m,0,~{memory},~{$1}"(ptr nonnull elementtype(ptr) [[P_ADDR]], ptr [[P]]) #[[ATTR1]], !srcloc !2
// HYBRID-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[P_ADDR]], align 8, !tbaa [[TBAA6]]
// HYBRID-NEXT:    ret ptr [[TMP0]]
//
// PURECAP-LABEL: define {{[^@]+}}@_Z8test_ptrPv
// PURECAP-SAME: (ptr addrspace(200) noundef [[P:%.*]]) local_unnamed_addr addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[P_ADDR:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
// PURECAP-NEXT:    store ptr addrspace(200) [[P]], ptr addrspace(200) [[P_ADDR]], align 16, !tbaa [[TBAA6:![0-9]+]]
// PURECAP-NEXT:    call void asm sideeffect "clb $$zero, $$zero, $0", "=*r|m,0,~{memory},~{$1}"(ptr addrspace(200) nonnull elementtype(ptr addrspace(200)) [[P_ADDR]], ptr addrspace(200) [[P]]) #[[ATTR1]], !srcloc !2
// PURECAP-NEXT:    [[TMP0:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[P_ADDR]], align 16, !tbaa [[TBAA6]]
// PURECAP-NEXT:    ret ptr addrspace(200) [[TMP0]]
//
void* test_ptr(void* p) {
  DoNotOptimize(p);
  return p;
}
