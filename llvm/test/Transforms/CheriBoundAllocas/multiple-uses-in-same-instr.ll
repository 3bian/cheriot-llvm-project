; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes
; This IR (reduced from compiling libkscreen) resulted in an invalid PHI node being generated
; in the CheriBoundAllocas pass. We now ensure that multiple uses within the same instruction
; reuse the same intrinsic call to avoid this problem.
; RUN: opt -instsimplify -cheri-bound-allocas -S < %s | FileCheck %s --check-prefix=OPAQUE
target datalayout = "e-m:e-pf200:128:128:128:64-p:64:64-i64:64-i128:128-n64-S128-A200-P200-G200"
target triple = "riscv64-unknown-freebsd13"

%class.QString = type { ptr addrspace(200) }
%struct.QTypedArrayData = type { %struct.QArrayData }
%struct.QArrayData = type { i32, i32, i32, ptr addrspace(200) }

declare void @use_QString(ptr addrspace(200)) addrspace(200)

define hidden void @multiple_uses_phi(i32 %arg) addrspace(200) {
; OPAQUE-LABEL: define {{[^@]+}}@multiple_uses_phi
; OPAQUE-SAME: (i32 [[ARG:%.*]]) addrspace(200) {
; OPAQUE-NEXT:  entry:
; OPAQUE-NEXT:    [[REF_TMP107:%.*]] = alloca [[CLASS_QSTRING:%.*]], align 16, addrspace(200)
; OPAQUE-NEXT:    br label [[COND_TRUE:%.*]]
; OPAQUE:       cond.true:
; OPAQUE-NEXT:    [[TMP0:%.*]] = call ptr addrspace(200) @llvm.cheri.bounded.stack.cap.i64(ptr addrspace(200) [[REF_TMP107]], i64 16)
; OPAQUE-NEXT:    switch i32 [[ARG]], label [[COND_END_SINK_SPLIT:%.*]] [
; OPAQUE-NEXT:    i32 -1, label [[COND_END:%.*]]
; OPAQUE-NEXT:    i32 0, label [[COND_END]]
; OPAQUE-NEXT:    ]
; OPAQUE:       cond.end.sink.split:
; OPAQUE-NEXT:    br label [[COND_END]]
; OPAQUE:       cond.end:
; OPAQUE-NEXT:    [[REF_TMP109_SINK:%.*]] = phi ptr addrspace(200) [ [[TMP0]], [[COND_TRUE]] ], [ [[TMP0]], [[COND_TRUE]] ], [ null, [[COND_END_SINK_SPLIT]] ]
; OPAQUE-NEXT:    call void @use_QString(ptr addrspace(200) [[REF_TMP109_SINK]])
; OPAQUE-NEXT:    ret void
;
entry:
  %ref.tmp107 = alloca %class.QString, align 16, addrspace(200)
  br label %cond.true

cond.true:                                        ; preds = %entry
  switch i32 %arg, label %cond.end.sink.split [
  i32 -1, label %cond.end
  i32 0, label %cond.end
  ]

cond.end.sink.split:                              ; preds = %cond.true
  br label %cond.end

cond.end:                                         ; preds = %cond.end.sink.split, %cond.true, %cond.true
  %ref.tmp109.sink = phi ptr addrspace(200) [ %ref.tmp107, %cond.true ], [ %ref.tmp107, %cond.true ], [ null, %cond.end.sink.split ]
  call void @use_QString(ptr addrspace(200) %ref.tmp109.sink)
  ret void
}

declare void @use_two_i64s(ptr addrspace(200), ptr addrspace(200)) addrspace(200)

define hidden void @multiple_uses_call() addrspace(200) {
; OPAQUE-LABEL: define {{[^@]+}}@multiple_uses_call() addrspace(200) {
; OPAQUE-NEXT:  entry:
; OPAQUE-NEXT:    [[FOO:%.*]] = alloca i64, align 8, addrspace(200)
; OPAQUE-NEXT:    [[TMP0:%.*]] = call ptr addrspace(200) @llvm.cheri.bounded.stack.cap.i64(ptr addrspace(200) [[FOO]], i64 8)
; OPAQUE-NEXT:    call void @use_two_i64s(ptr addrspace(200) [[TMP0]], ptr addrspace(200) [[TMP0]])
; OPAQUE-NEXT:    [[TMP1:%.*]] = call ptr addrspace(200) @llvm.cheri.bounded.stack.cap.i64(ptr addrspace(200) [[FOO]], i64 8)
; OPAQUE-NEXT:    call void @use_two_i64s(ptr addrspace(200) [[TMP1]], ptr addrspace(200) [[TMP1]])
; OPAQUE-NEXT:    ret void
;
entry:
  %foo = alloca i64, align 8, addrspace(200)
  call void @use_two_i64s(ptr addrspace(200) %foo, ptr addrspace(200) %foo)
  ; This second call should insert another intrinsic call:
  call void @use_two_i64s(ptr addrspace(200) %foo, ptr addrspace(200) %foo)
  ret void
}

declare void @use_i32(ptr addrspace(200)) addrspace(200)

define hidden void @multiple_uses_different_blocks_phi(i32 %arg) addrspace(200) {
; OPAQUE-LABEL: define {{[^@]+}}@multiple_uses_different_blocks_phi
; OPAQUE-SAME: (i32 [[ARG:%.*]]) addrspace(200) {
; OPAQUE-NEXT:  entry:
; OPAQUE-NEXT:    [[FOO:%.*]] = alloca i32, align 4, addrspace(200)
; OPAQUE-NEXT:    switch i32 [[ARG]], label [[COND_END:%.*]] [
; OPAQUE-NEXT:    i32 0, label [[COND_0:%.*]]
; OPAQUE-NEXT:    i32 1, label [[COND_1:%.*]]
; OPAQUE-NEXT:    ]
; OPAQUE:       cond.0:
; OPAQUE-NEXT:    [[TMP0:%.*]] = call ptr addrspace(200) @llvm.cheri.bounded.stack.cap.i64(ptr addrspace(200) [[FOO]], i64 4)
; OPAQUE-NEXT:    br label [[COND_END]]
; OPAQUE:       cond.1:
; OPAQUE-NEXT:    [[TMP1:%.*]] = call ptr addrspace(200) @llvm.cheri.bounded.stack.cap.i64(ptr addrspace(200) [[FOO]], i64 4)
; OPAQUE-NEXT:    br label [[COND_END]]
; OPAQUE:       cond.end:
; OPAQUE-NEXT:    [[PHI:%.*]] = phi ptr addrspace(200) [ null, [[ENTRY:%.*]] ], [ [[TMP0]], [[COND_0]] ], [ [[TMP1]], [[COND_1]] ]
; OPAQUE-NEXT:    call void @use_i32(ptr addrspace(200) [[PHI]])
; OPAQUE-NEXT:    ret void
;
entry:
  %foo = alloca i32, align 4, addrspace(200)
  switch i32 %arg, label %cond.end [
  i32 0, label %cond.0
  i32 1, label %cond.1
  ]

cond.0:                                           ; preds = %entry
  br label %cond.end

cond.1:                                           ; preds = %entry
  br label %cond.end

cond.end:                                         ; preds = %cond.1, %cond.0, %entry
  ; Repeated uses for different incoming blocks must not share a use from one
  ; of them as it may not dominate the other (alternatively we could insert it
  ; in the dominator, but in general that could be expensive).
  %phi = phi ptr addrspace(200) [ null, %entry ], [ %foo, %cond.0 ], [ %foo, %cond.1 ]
  call void @use_i32(ptr addrspace(200) %phi)
  ret void
}
